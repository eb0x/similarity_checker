{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0057125a",
   "metadata": {},
   "source": [
    "## Jupyter Notebook Collusion Detector\n",
    "\n",
    "&copy; Jeremy Ellman 28/02/2022 (v1). MIT License\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab37a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use jupyter to convert notebooks (.ipynb) to python (py). This will also save Markdown as comments\n",
    "#\n",
    "!jupyter nbconvert --to script --no-prompt /home/notebookuser/working/Colludo/Sources/*.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c26c214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Global Paremeters\n",
    "verbose = False #prints full file names\n",
    "similarity_threshold = 0.8  #Value depends on amount of standard code used -- vary up if more standard code is used.\n",
    "output_file = '/home/notebookuser/working/Colludo/Sources/copies.csv'\n",
    "source_path = '/home/notebookuser/working/Colludo/Sources/'\n",
    "file_type = \".py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b34c4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect list of code_files to analyse\n",
    "#\n",
    "code_files = [source_path + filename for filename in os.listdir(source_path) if filename.endswith(file_type)]\n",
    "\n",
    "if verbose:\n",
    "    print(f'There are {len(code_files)} to process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9d8c49aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove irrelevant (i.e. text/comments) from a line\n",
    "#\n",
    "def remove_irrelevant(line):\n",
    "    line = line.strip()                           #remove whitespace at and end start\n",
    "    line = re.sub(\"#.*$\", \"\", line)               #strip comments\n",
    "    line = re.sub(\"^import.*\", \"\", line)          #remove import statements\n",
    "    line = re.sub(\"^from.*\", \"\", line)\n",
    "    line = re.sub(\"^get_ipython.*\", \"\", line)     #strip cell-magic\n",
    "    return line\n",
    "\n",
    "## read in a file and strip irrelevant content\n",
    "#\n",
    "def preprocess(filename):\n",
    "    lineslist = \"\"\n",
    "    with open(filename) as f:\n",
    "        for line in f.read().splitlines():\n",
    "            line = remove_irrelevant(line)\n",
    "            if line != \"\":                      #only retain none-blank lines after comment stripping\n",
    "                lineslist += ' ' + line\n",
    "    return lineslist\n",
    "\n",
    "# Documents are the files as list of lines\n",
    "#\n",
    "documents = [preprocess(filename) for filename in code_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18910a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf/idf vectors of the documents using sklearn and compute their similarity\n",
    "# (Thanks to https://stackoverflow.com/questions/8897593/how-to-compute-the-similarity-between-two-text-documents)\n",
    "\n",
    "tfidf = TfidfVectorizer().fit_transform(documents)\n",
    "pairwise_similarity = tfidf * tfidf.T\n",
    "results_array = pairwise_similarity.toarray() #compute the cosine similarity into square similarity matrix\n",
    "np.fill_diagonal(results_array, np.nan) #mask the 1's, which represent the similarity of each document to itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc7996a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Global record of file similarities\n",
    "copies_dict = dict()\n",
    "\n",
    "cheating_detected = True\n",
    "\n",
    "#Here we report on pair wise similarities. Since groups often collude we repeat the process until all pairs are found\n",
    "#\n",
    "while cheating_detected:\n",
    "    cheating_detected = False\n",
    "    for i in range(len(code_files)):\n",
    "        max_sim = np.nanargmax(results_array[i])\n",
    "        first = code_files[i]\n",
    "        similarity_score = results_array[i, max_sim]\n",
    "        if (similarity_score > similarity_threshold) & (first not in copies_dict):\n",
    "            second = code_files[max_sim]\n",
    "            copies_dict[first] = [second, similarity_score]\n",
    "            if verbose:\n",
    "                print(f\"File: {first}\\n max_sim: {second}, Score: {similarity_score:.2f} \")\n",
    "            results_array[i, max_sim] = np.nan #don't re-find this pair\n",
    "            results_array[max_sim, i] = np.nan\n",
    "            cheating_detected = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "926225b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "## Write the output as csv file\n",
    "#\n",
    "with open(output_file, 'w') as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"First File\", \"Second File\", \"Similarity Score\"])\n",
    "    for key, value in copies_dict.items():\n",
    "        src = os.path.basename(key)\n",
    "        dest = os.path.basename(value[0])\n",
    "        score = \"{:.2f}\".format(value[1])\n",
    "        writer.writerow([src, dest, score])\n",
    "        \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84466b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
